<p align="center">
  <img src="/Llama_Repo.jpeg" width="400"/>
</p>

<p align="center">
        ðŸ¤— <a href="https://huggingface.co/meta-Llama"> Models on Hugging Face</a>&nbsp | <a href="https://ai.meta.com/blog/"> Blog</a>&nbsp |  <a href="https://llama.meta.com/">Website</a>&nbsp | <a href="https://llama.meta.com/get-started/">Get Started</a>&nbsp
<br>

---

# A simple flask code to host LLAMA model

This repository is clone of https://github.com/meta-llama/llama-models, with files added to host the model as a server, locally, and than call it via API.
 - multimedia_server.py code of server.
 - simple_client.py it is a stand alone code, just to illustrate how to call the server. One may need to modify the IP in the url.
 - run_server.sh: source run_server.sh should run the server.

